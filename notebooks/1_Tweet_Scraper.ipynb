{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1 - Tweet Scraper.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bvA5BEQV0Tsh"
      },
      "source": [
        "This notebook contains the code used for collecting tweet data on politicians in the U.S. senate and house of representatives. I used Tweepy to access the Twitter API through Python. Note that without your own authentication for the Twitter API, you will not be able to test this notebook. You can apply for a Twitter Developer account at https://developer.twitter.com"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KgZ6BoWC0Otb"
      },
      "source": [
        "import tweepy\n",
        "import time"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "umnU8Qzz0uCi"
      },
      "source": [
        "Using Tweepy requires authentication from Twitter. I applied for a Twitter development account, and once this was approved, I was able to get the key and secret to access the API. For privacy, I have removed the actual key and secret from the cell below.\n",
        "\n",
        "To learn how to use Tweepy, I used the resource here: https://towardsdatascience.com/how-to-scrape-tweets-from-twitter-59287e20f0f1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vv_L0tYS1AwJ"
      },
      "source": [
        "consumer_key = \"your key here\"\n",
        "consumer_secret = \"your secret here\"\n",
        "\n",
        "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
        "api = tweepy.API(auth)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EIfU1Q2a1cL_"
      },
      "source": [
        "To find Twitter handles for all politicians in congress, I used the following source: https://triagecancer.org/congressional-social-media\n",
        "\n",
        "Some of the handles were out of date, or have been deleted, so I copied the data from the site above into a csv file, and updated it as needed. This file is included in the github repository for this project.\n",
        "\n",
        "The following block of code loads this csv file from my Google drive, into a pandas dataframe.\n",
        "\n",
        "We take a peak at the first few lines of this dataframe, seeing that we have the state and/or district, branch of government, last name, first name, party, and Twitter handle for each politician."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "id": "5hVIuCGl2WZ9",
        "outputId": "a2560c62-2438-40ac-f98f-86dac71587ca"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "link = \"https://raw.githubusercontent.com/lynn0032/CourseProject/main/data_files/twitter_handles.csv\"\n",
        "\n",
        "politicians_df = pd.read_csv(link)\n",
        "\n",
        "politicians_df.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>State</th>\n",
              "      <th>Branch</th>\n",
              "      <th>Last Name</th>\n",
              "      <th>First Name</th>\n",
              "      <th>Party</th>\n",
              "      <th>Twitter Handle</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Alabama</td>\n",
              "      <td>U.S. Senator</td>\n",
              "      <td>Shelby</td>\n",
              "      <td>Richard</td>\n",
              "      <td>R</td>\n",
              "      <td>SenShelby</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Alabama</td>\n",
              "      <td>U.S. Senator</td>\n",
              "      <td>Tuberville</td>\n",
              "      <td>Tommy</td>\n",
              "      <td>R</td>\n",
              "      <td>Ttuberville</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Alabama 1st District</td>\n",
              "      <td>U.S. Representative</td>\n",
              "      <td>Carl</td>\n",
              "      <td>Jerry</td>\n",
              "      <td>R</td>\n",
              "      <td>RepJerryCarl</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Alabama 2nd District</td>\n",
              "      <td>U.S. Representative</td>\n",
              "      <td>Moore</td>\n",
              "      <td>Barry</td>\n",
              "      <td>R</td>\n",
              "      <td>RepBarryMoore</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Alabama 3rd District</td>\n",
              "      <td>U.S. Representative</td>\n",
              "      <td>Rogers</td>\n",
              "      <td>Mike</td>\n",
              "      <td>R</td>\n",
              "      <td>RepMikeRogers</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                  State               Branch  ... Party Twitter Handle\n",
              "0               Alabama         U.S. Senator  ...     R      SenShelby\n",
              "1               Alabama         U.S. Senator  ...     R    Ttuberville\n",
              "2  Alabama 1st District  U.S. Representative  ...     R   RepJerryCarl\n",
              "3  Alabama 2nd District  U.S. Representative  ...     R  RepBarryMoore\n",
              "4  Alabama 3rd District  U.S. Representative  ...     R  RepMikeRogers\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3R1oXP2E3M5_"
      },
      "source": [
        "The following block of code creates a dataframe to store the information for all tweets. For each tweet, we store the handle, timestamp, ID, and text of the tweet.\n",
        "\n",
        "The count, here 18, determines how many tweets are retrieved for each account. This number is limited, because the Twitter API only allows accessing about 10,000 tweets a day. \n",
        "\n",
        "For each handle, I create a dataframe with the most recent tweets from that user. These are temporarily stored in a dataframe user_tweets_df, and exported to a csv file in my drive, as a backup. The dataframe user_tweets_df is also concatenated onto tweets_df, which collects the tweets from all users.\n",
        "\n",
        "Once all of the tweets are collected, the dataframe tweets_df is joined with the dataframe politicians_df created above. The rows of the merged dataframe each represent a single tweet, and also include information on the politician who wrote the tweet (including their name and party). The dataframe tweets_df is exported to a csv file, to be stored and used later."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D5zi8D-w3LLy",
        "outputId": "29cb57fd-fc3f-4429-cef4-0e4da623fc92"
      },
      "source": [
        "# Mount google drive\n",
        "from google.colab import drive \n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "# This can be replaced with a location on your own drive\n",
        "drive_location = 'gdrive/My Drive/CS 410 Text Information Systems/Final Project/Tweets/'\n",
        "\n",
        "column_names = [\"Twitter Handle\", \"Created At\", \"ID\", \"Tweet Text\"]\n",
        "tweets_df = pd.DataFrame(columns = column_names)\n",
        "\n",
        "count = 18\n",
        "\n",
        "for username in politicians_df[\"Twitter Handle\"]:\n",
        "  try:\n",
        "    tweets = tweepy.Cursor(api.user_timeline,id=username).items(count)\n",
        "    tweets_list = [[tweet.created_at, tweet.id, tweet.text] for tweet in tweets]\n",
        "    tweets_list = [[username] + tweet for tweet in tweets_list]\n",
        "    user_tweets_df = pd.DataFrame(tweets_list, columns = column_names)\n",
        "    tweets_df = pd.concat([tweets_df, user_tweets_df], axis = 0)\n",
        "    user_tweets_df.to_csv(drive_location + str(username) + \".csv\")\n",
        "  except BaseException as e:\n",
        "    print(\"Failed on_status,\", str(e), \"for account\", username)\n",
        "    time.sleep(3)\n",
        "\n",
        "tweets_dataset = pd.merge(tweets_df, politicians_df, how = \"right\", on = [\"Twitter Handle\"])\n",
        "tweets_dataset.to_csv(drive_location + \"all_tweets.csv\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qmCh2h8b4znp"
      },
      "source": [
        "In order to create a dataset of tweets, I ran the code above every evening from 11/15/21 through 11/26/21. In a subsequent notebook, we'll see that (after removing duplicate tweets), this resulted in 84,948 tweets collected."
      ]
    }
  ]
}