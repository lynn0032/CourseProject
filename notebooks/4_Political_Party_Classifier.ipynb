{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "4 - Political Party Classifier.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cW0Yse4Di0of"
      },
      "source": [
        "In this notebook, we use the tweet data assembled as in Notebook 2 - Data Preprocessing, and use this data to train political party classifiers. We use cross validation to evaluate the accuracy of these classifiers.\n",
        "\n",
        "# Setup\n",
        "\n",
        "In this section, we repeat the code from Notebook 2 - Data Preprocessing, which sets up the data structures that we use for analysis. The code here is included without explanation, for the documentation for this code, refer back to Notebook 2."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_uU5MJ3lfg4C"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# List of dates for which data was gathered. This is used in the file names.\n",
        "dates = [\"11\" + str(day) for day in range(15, 27)]\n",
        "\n",
        "# Location of the csv files containing tweets\n",
        "location = \"https://raw.githubusercontent.com/lynn0032/CourseProject/main/data_files/\"\n",
        "\n",
        "column_names = [\"Index\", \"Twitter Handle\", \"Created At\", \"ID\", \"Tweet Text\", \"State\", \"Branch\", \"Last Name\", \"First Name\"]\n",
        "tweets_df = pd.DataFrame(columns = column_names)\n",
        "\n",
        "# Load tweet data from each day, and combine them in the dataframe tweets_df\n",
        "for d in dates:\n",
        "  file_name = \"all_tweets_\" + d + \".csv\"\n",
        "  day_df = pd.read_csv(location + file_name)\n",
        "  tweets_df = pd.concat([tweets_df, day_df], axis = 0)\n",
        "\n",
        "#Drop the extra Index column\n",
        "tweets_df = tweets_df.drop(columns = [\"Index\"])"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wfXHyw-SjA4c"
      },
      "source": [
        "#Remove duplicate tweets\n",
        "tweets_df = tweets_df.drop_duplicates()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "okHvRBU2j9Jw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "19df20e5-5c29-4a0b-e0b4-f53eb352d7a0"
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vxo5IK6CkBCb"
      },
      "source": [
        "def remove_punctuation(word:str) -> str:\n",
        "  \"\"\"Takes a word, and returns the word with characters \n",
        "  except for lowercase letters and @ and # removed\"\"\"\n",
        "  new_word = \"\"\n",
        "  allowed = \"abcdefghijklmnopqrstuvwxyz@#\"\n",
        "  for char in word:\n",
        "    if char in allowed:\n",
        "      new_word += char\n",
        "  return new_word\n",
        "\n",
        "stop_words = stopwords.words('english')     #stop words from nltk\n",
        "\n",
        "def get_words(text_str) -> list:\n",
        "  \"\"\"Takes a tweet, splits it into words based on spaces,\n",
        "  removes extra punctuation from the words, and then\n",
        "  removes stop words\"\"\"\n",
        "  words = [remove_punctuation(w.lower()) for w in text_str.split(\" \")]\n",
        "  filtered_words = [w for w in words if w not in stop_words]\n",
        "  return [word for word in filtered_words if word != \"\"]"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tu3ICkZJkGEN"
      },
      "source": [
        "def retweet(words:list) -> bool:\n",
        "  \"\"\"Takes a list of words from a tweet (as returned by get_words), \n",
        "  and returns True if 'rt' is one of the words (which means that \n",
        "  the tweet is a retweet)\"\"\"\n",
        "  return ('rt' in words)\n",
        "\n",
        "def tweet_at(words:list) -> list:\n",
        "  \"\"\"Takes a list of words from a tweet (as returned by get_words),\n",
        "  and returns a list of handles that are tweeted at in the tweet\"\"\"\n",
        "  at = []\n",
        "  for word in words:\n",
        "    if word[0] == '@':\n",
        "      at.append(word[1:])\n",
        "  return at\n",
        "\n",
        "def hash_tags(words:list) -> list:\n",
        "  \"\"\"Takes a list of words from a tweet (as returned by get_words),\n",
        "  and returns a list of all hashtags included in the tweet\"\"\"\n",
        "  tags = []\n",
        "  for word in words:\n",
        "    if word[0] == '#':\n",
        "      tags.append(word[1:])\n",
        "  return tags"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YZp8sZHDkM6_"
      },
      "source": [
        "ps = PorterStemmer()    # Word stemmer from nltk\n",
        "\n",
        "def word_counts(words:list) -> dict:\n",
        "  \"\"\"Takes a list of words from a tweet (as returned by get_words),\n",
        "  and returns a dictionary of the counts of words from the tweet\"\"\"\n",
        "  counts_dict = {}\n",
        "  for word in words:\n",
        "    if word[0] != '@' and word[0] != '#' and word != 'rt' and 'http' not in word:\n",
        "      word = ps.stem(word)\n",
        "      if word in counts_dict:\n",
        "        counts_dict[word] += 1\n",
        "      else:\n",
        "        counts_dict[word] = 1\n",
        "  return counts_dict"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v9uRkdWEkSRv"
      },
      "source": [
        "def parse_tweet(text:str) -> dict:\n",
        "  words = get_words(text)\n",
        "  return {\"counts\": word_counts(words), \"retweet\": retweet(words), \"at\": tweet_at(words), \"tags\": hash_tags(words)}\n",
        "  \n",
        "tweet_dict = {}\n",
        "for tweet in tweets_df['Tweet Text']:\n",
        "  tweet = str(tweet)\n",
        "  tweet_dict[tweet] = parse_tweet(tweet)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "23DYXzL9kbPm"
      },
      "source": [
        "handle_parties_df = tweets_df[['Twitter Handle', 'Party']]\n",
        "handle_parties_df.drop_duplicates()\n",
        "parties = {}\n",
        "for index, row in handle_parties_df.iterrows():\n",
        "  handle = row['Twitter Handle']\n",
        "  parties[handle] = row['Party']"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bitG-9ok8dRo"
      },
      "source": [
        "def handle_word_counts(handle):\n",
        "  handle_df = tweets_df[tweets_df['Twitter Handle'] == handle]\n",
        "  all_counts = {}\n",
        "  for tweet in handle_df['Tweet Text']:\n",
        "    tweet = str(tweet)\n",
        "    for word in tweet_dict[tweet]['counts']:\n",
        "      if word in all_counts:\n",
        "        all_counts[word] += tweet_dict[tweet]['counts'][word]\n",
        "      else:\n",
        "        all_counts[word] = tweet_dict[tweet]['counts'][word]\n",
        "  return all_counts"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oI8yHnKL8hI2"
      },
      "source": [
        "handles = list(set(tweets_df['Twitter Handle'].unique()))\n",
        "\n",
        "handle_counts_dict = {}\n",
        "for handle in handles:\n",
        "  handle_counts_dict[handle] = handle_word_counts(handle)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z1o1cNo7rL45"
      },
      "source": [
        "# Training a Political Party Classifier, and Evaluating it's Accuracy\n",
        "\n",
        "Now, we will explore how accurately we can classify accounts or individual tweets by political party based on only the text of tweets. In order to do this, we divide the dataset into a training set and a testing set. We use the training set to build a topic model for tweets by democrats, then use a maximum likelihood classifier to predict the party of accounts/tweets in the test set. These are compared with their actual party, to evaluate the accuracy of the classifier. We use cross-validation to evaluate the classifier over multiple different training-testing splits.\n",
        "We begin by building a classifier to classify accounts as democrat or republican. We build a list of handles from the dataset, shuffle this list, and divide it into  ð‘˜  groups (for  ð‘˜ -fold cross-validation)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "00R6EVeQrK98"
      },
      "source": [
        "import random\n",
        "\n",
        "# Number of folds for cross validation\n",
        "num_folds = 5\n",
        "\n",
        "# Shuffle list of handles\n",
        "random.seed(7)         # Added so that results are consistent, delete for a random split\n",
        "random.shuffle(handles)\n",
        "\n",
        "# Divide list of handles\n",
        "num_handles = len(handles)\n",
        "folds = []\n",
        "for num in range(num_folds):\n",
        "  folds.append(handles[round(num / num_folds * num_handles) : round((num + 1) / num_folds * num_handles)])\n",
        "\n",
        "# Create list of training dataframes, each one omitting one of the folds\n",
        "all_train_df = [tweets_df for index in range(num_folds)]\n",
        "for index in range(num_folds):\n",
        "  for handle in folds[index]:\n",
        "    all_train_df[index] = all_train_df[index][(all_train_df[index]['Twitter Handle'] != handle)]"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sCvPVbd4rw8U"
      },
      "source": [
        "For each of the training data frames, we build a topic model for the democrats and republicans based on that dataframe, finding the word frequencies for each party within the training set.\n",
        "\n",
        "In order to do this, we begin by defining a function party_counts, which takes a dataframe of tweets (one of the training set), and returns a dictionary giving word counts for democrats and a dictionary of word counts for republicans."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RMIkRRfArvpI"
      },
      "source": [
        "def party_counts(train_df):\n",
        "  \"\"\"Takes a dataframe of tweets (one of the training sets),\n",
        "  and returns two dictionaries: one with the word counts for democrats\n",
        "  in the training set, and one with word counts for republicans.\"\"\"\n",
        "\n",
        "  dem_counts = {}\n",
        "  rep_counts = {}\n",
        "\n",
        "  for index, row in train_df.iterrows():\n",
        "    tweet = str(row['Tweet Text'])\n",
        "    words = tweet_dict[tweet]['counts']\n",
        "    for word in words:\n",
        "      if str(row['Party']) == 'D':\n",
        "        if word in dem_counts:\n",
        "          dem_counts[word] += words[word]\n",
        "        else:\n",
        "          dem_counts[word] = words[word]\n",
        "      if str(row['Party']) == \"R\":\n",
        "        if word in rep_counts:\n",
        "          rep_counts[word] += words[word]\n",
        "        else:\n",
        "          rep_counts[word] = words[word]\n",
        "  return (dem_counts, rep_counts)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VtbP840dsPb4"
      },
      "source": [
        "Now, we define a function that adds pseudocounts for unseen words to the topic models, for smoothing. For our purposes, we will take the vocabulary to be all words that appear in the entire dataset of tweets (as parsed by the preprocessing functions). When a classifier encountered an unseen word, we will ignore the word. Since we are focused on comparing frequencies between the two parties, this shouldn't affect the results.\n",
        "\n",
        "For the pseudocounts, we add one to the count for every word in the vocabulary."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PD3oOYP4sM7_"
      },
      "source": [
        "def add_pseudo_counts(word_dict:dict, vocab):\n",
        "  \"\"\"Adds pseudo counts to the word_dict, +1 for each word in the vocabulary\"\"\"\n",
        "  for word in vocab:\n",
        "    if word in word_dict:\n",
        "      word_dict[word] += 1\n",
        "    else:\n",
        "      word_dict[word] = 1"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r0GRBky_sTox"
      },
      "source": [
        "Finally, we normalize the counts by the total of all counts within the dictionary. We compute this result for democrat and republican word counts for each of our training sets, constructed for cross-validation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_OgXQ75JsS38"
      },
      "source": [
        "def count_to_freq(count_dict:dict) -> dict:\n",
        "  total_counts = sum(count_dict.values())\n",
        "  freq_dict = {}\n",
        "  for word in count_dict:\n",
        "    freq_dict[word] = count_dict[word] / total_counts\n",
        "  return freq_dict\n",
        "\n",
        "vocab = []\n",
        "for tweet in tweet_dict:\n",
        "  for word in tweet_dict[tweet][\"counts\"]:\n",
        "    vocab.append(word)\n",
        "\n",
        "word_counts = [party_counts(train_df) for train_df in all_train_df]\n",
        "for train_set in word_counts:\n",
        "  for word_dict in train_set:\n",
        "    add_pseudo_counts(word_dict, vocab)\n",
        "freq_dicts = [[count_to_freq(word_dict) for word_dict in train_dicts] for train_dicts in word_counts]"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e8Bz5I1rt4lP"
      },
      "source": [
        "Now that the training sets are ready to create a maximum likelihood classifier, and for the test sets, we use the dictionary of word counts for each handle. So, we are ready to define the functions that will be used for the maximum likelihood classifier.\n",
        "\n",
        "The function log_prob computes the log probability of generating the collection of words given by handle_counts, from the distribution word_dist. This will be applied to the collection of words for a handle in the test set, with the word distribution from the training set for one of the parties, to compute how likely it is that the topic model for that party generated the account's tweets.\n",
        "\n",
        "The function predict compares the log probabilities, to give a prediction of whether the account is from a democrat or from a republican."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CBP6DTFLuBKI"
      },
      "source": [
        "import math\n",
        "\n",
        "def log_prob(word_dist, handle_counts):\n",
        "  \"\"\"Takes a word distribution, and a dictionary of word counts.\n",
        "  Returns the log probability of generating the collection of words \n",
        "  in the dictionary from the given word distribution\"\"\"\n",
        "  result = 0\n",
        "  for word in handle_counts:\n",
        "    if word in word_dist:\n",
        "      result += handle_counts[word] * math.log(word_dist[word])\n",
        "  return result\n",
        "\n",
        "def predict(dem_prob, rep_prob):\n",
        "  \"\"\"Compares log probability for democrat and for republican, \n",
        "  and returns 'D' if democrat is more likely, 'R' if republican\n",
        "  is more likely\"\"\"\n",
        "  if dem_prob > rep_prob:\n",
        "    return \"D\"\n",
        "  else:\n",
        "    return \"R\""
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gQmutM89uGh1"
      },
      "source": [
        "Now, we define a function that evaluates the maximum likelihood classifier on a set of test handles, and prints the accuracy, as well as the counts of misclassification errors. For each misclassification, we also print the handle and the log probabilities. Finally, we return the accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YkNgnRp1uGA1"
      },
      "source": [
        "def evaluate(dem_dist, rep_dist, handles):\n",
        "  total = 0\n",
        "  total_correct = 0\n",
        "  rep_as_dem = 0\n",
        "  dem_as_rep = 0\n",
        "  other_mis = 0\n",
        "  for handle in handles:\n",
        "    dem_prob = log_prob(dem_dist, handle_counts_dict[handle])\n",
        "    rep_prob = log_prob(rep_dist, handle_counts_dict[handle])\n",
        "    prediction = predict(dem_prob, rep_prob)\n",
        "    actual = parties[handle]\n",
        "\n",
        "    total += 1\n",
        "    if actual == prediction:\n",
        "      total_correct += 1\n",
        "    else:\n",
        "      print(\"Misclassified:\", handle, \"\\n\\tDemocrat log prob:\", dem_prob, \"\\n\\tRepublican log prob:\", rep_prob)\n",
        "      if actual == \"D\" and prediction == \"R\":\n",
        "        dem_as_rep += 1\n",
        "      elif actual == \"R\" and prediction == \"D\":\n",
        "        rep_as_dem += 1\n",
        "      else:\n",
        "        other_mis +=1\n",
        "  accuracy = total_correct / total\n",
        "  print(\"Accuracy:\", accuracy)\n",
        "  print(\"Misclassified Dem as Rep:\", dem_as_rep)\n",
        "  print(\"Misclassified Rep as Dem:\", rep_as_dem)\n",
        "  print(\"Misclassified other:\", other_mis) \n",
        "  return accuracy     "
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7J7rMTzNuMU4"
      },
      "source": [
        "Now, we apply the evaluation function to all of folds for cross-validation, printing the results, and computing and printing the average accuracy across all folds."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HV3KIy33uKLA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c1fb97d-9dbd-4835-f556-2cde65213e90"
      },
      "source": [
        "total_accuracy = 0\n",
        "for index in range(num_folds):\n",
        "  test_handles = folds[index]\n",
        "  dem_dist = freq_dicts[index][0]\n",
        "  rep_dist = freq_dicts[index][1]\n",
        "  print(\"*************************\\nResults for fold\", index)\n",
        "  total_accuracy += evaluate(dem_dist, rep_dist, test_handles)\n",
        "\n",
        "print(\"*************************\\nAverage Accuracy:\", total_accuracy / num_folds)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*************************\n",
            "Results for fold 0\n",
            "Misclassified: SenSanders \n",
            "\tDemocrat log prob: -16003.70430073335 \n",
            "\tRepublican log prob: -15954.211345190217\n",
            "Misclassified: FrancisRooney \n",
            "\tDemocrat log prob: -2704.842047002437 \n",
            "\tRepublican log prob: -2735.5398679225204\n",
            "Misclassified: MarkAmodeiNV2 \n",
            "\tDemocrat log prob: -3740.32921310178 \n",
            "\tRepublican log prob: -3780.17318187544\n",
            "Misclassified: IlhanMN \n",
            "\tDemocrat log prob: -15322.211605446817 \n",
            "\tRepublican log prob: -15308.939877402607\n",
            "Misclassified: RepBryanSteil \n",
            "\tDemocrat log prob: -12450.846729265071 \n",
            "\tRepublican log prob: -12355.625535986554\n",
            "Misclassified: Donald_McEachin \n",
            "\tDemocrat log prob: -5104.202829070854 \n",
            "\tRepublican log prob: -5123.625538606095\n",
            "Accuracy: 0.9439252336448598\n",
            "Misclassified Dem as Rep: 2\n",
            "Misclassified Rep as Dem: 3\n",
            "Misclassified other: 1\n",
            "*************************\n",
            "Results for fold 1\n",
            "Misclassified: BuddforCongress \n",
            "\tDemocrat log prob: -36.559338908084925 \n",
            "\tRepublican log prob: -37.37632499725778\n",
            "Accuracy: 0.9907407407407407\n",
            "Misclassified Dem as Rep: 0\n",
            "Misclassified Rep as Dem: 1\n",
            "Misclassified other: 0\n",
            "*************************\n",
            "Results for fold 2\n",
            "Misclassified: SenAngusKing \n",
            "\tDemocrat log prob: -15701.792888076741 \n",
            "\tRepublican log prob: -15975.798682882763\n",
            "Misclassified: RepSteveStivers \n",
            "\tDemocrat log prob: -4414.227670753553 \n",
            "\tRepublican log prob: -4417.585888869735\n",
            "Misclassified: RepFredUpton \n",
            "\tDemocrat log prob: -17307.13385161359 \n",
            "\tRepublican log prob: -17442.769024381956\n",
            "Misclassified: lisamurkowski \n",
            "\tDemocrat log prob: -15625.158765623535 \n",
            "\tRepublican log prob: -15724.672567679585\n",
            "Misclassified: RepJoeNeguse \n",
            "\tDemocrat log prob: -14102.993737845925 \n",
            "\tRepublican log prob: -14530.889343806117\n",
            "Accuracy: 0.9532710280373832\n",
            "Misclassified Dem as Rep: 0\n",
            "Misclassified Rep as Dem: 4\n",
            "Misclassified other: 1\n",
            "*************************\n",
            "Results for fold 3\n",
            "Misclassified: Nmalliotakis \n",
            "\tDemocrat log prob: -14039.609715934806 \n",
            "\tRepublican log prob: -13696.092341867068\n",
            "Misclassified: GuamCongressman \n",
            "\tDemocrat log prob: -2566.4421944199826 \n",
            "\tRepublican log prob: -2556.485896669117\n",
            "Misclassified: MaxineWaters \n",
            "\tDemocrat log prob: -2637.837092396387 \n",
            "\tRepublican log prob: -2618.106983892136\n",
            "Misclassified: RepJohnKatko \n",
            "\tDemocrat log prob: -12465.283680730134 \n",
            "\tRepublican log prob: -12542.187149787402\n",
            "Misclassified: RepDeanPhillips \n",
            "\tDemocrat log prob: -13731.49162377717 \n",
            "\tRepublican log prob: -13702.607270213644\n",
            "Accuracy: 0.9537037037037037\n",
            "Misclassified Dem as Rep: 4\n",
            "Misclassified Rep as Dem: 1\n",
            "Misclassified other: 0\n",
            "*************************\n",
            "Results for fold 4\n",
            "Misclassified: RepKinzinger \n",
            "\tDemocrat log prob: -7746.559221200747 \n",
            "\tRepublican log prob: -7762.019056837864\n",
            "Misclassified: Jamie_Raskin \n",
            "\tDemocrat log prob: -3070.8760431869264 \n",
            "\tRepublican log prob: -3062.2245985365025\n",
            "Misclassified: SenatorCollins \n",
            "\tDemocrat log prob: -2637.5962695956964 \n",
            "\tRepublican log prob: -2682.173555055979\n",
            "Misclassified: AlLawsonJr \n",
            "\tDemocrat log prob: -2187.9551954040016 \n",
            "\tRepublican log prob: -2174.57385922817\n",
            "Misclassified: CharlieCrist \n",
            "\tDemocrat log prob: -15264.968673580172 \n",
            "\tRepublican log prob: -15238.691519542162\n",
            "Accuracy: 0.9532710280373832\n",
            "Misclassified Dem as Rep: 3\n",
            "Misclassified Rep as Dem: 2\n",
            "Misclassified other: 0\n",
            "*************************\n",
            "Average Accuracy: 0.9589823468328141\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J9rOOJ2JuQDe"
      },
      "source": [
        "We see that our average accuracy for cross-validation is about 95.7%, which seems quite good. We note several interesting appearances in the misclassifications\n",
        "\n",
        "\n",
        "*   Bernie Sanders (SenSanders) and Angus King (SenAngusKing) are both independents, with party listed as I, and were misclassified. Since this classifier only predicts republican or democrat, this is expected.\n",
        "*   Lisa Murkowski (lisamurkowski) and Susan Collins (SenatorCollins) are republicans who were misclassified as democrats. These senators have been frequently discussed as voting with democrats in some cases, so it is interesting that their tweets align with the democrat topic models.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_hMfEKCRuWfC"
      },
      "source": [
        "The results above rely on grouping all tweets together for an account, and then classifying the account. We could also attempt to classify individual tweets by party, which is significantly more difficult because of how short tweets are. In the code below, we repeat our above work of using a maximum likelihood classifier and evaluate the results, this time for individual tweets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cYxC_0apuO6S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21dc65ba-9ac9-4084-f0a8-5507971402ef"
      },
      "source": [
        "def tweets_by_handle(handle):\n",
        "  handle_df = tweets_df[tweets_df['Twitter Handle'] == handle]\n",
        "  return handle_df[[\"Tweet Text\", \"Party\"]].dropna()\n",
        "\n",
        "def evaluate_individual_tweets(dem_dist, rep_dist, handle):\n",
        "  total = 0\n",
        "  total_correct = 0\n",
        "  rep_as_dem = 0\n",
        "  dem_as_rep = 0\n",
        "  other_mis = 0\n",
        "  for handle in handles:\n",
        "    tweets_with_party = tweets_by_handle(handle)\n",
        "    for index, row in tweets_with_party.iterrows():\n",
        "      tweet = str(row[\"Tweet Text\"])\n",
        "      dem_prob = log_prob(dem_dist, tweet_dict[row[\"Tweet Text\"]][\"counts\"])\n",
        "      rep_prob = log_prob(rep_dist, tweet_dict[row[\"Tweet Text\"]][\"counts\"])\n",
        "      prediction = predict(dem_prob, rep_prob)\n",
        "      actual = str(row[\"Party\"])\n",
        "\n",
        "      total += 1\n",
        "      if actual == prediction:\n",
        "        total_correct += 1\n",
        "      else:\n",
        "        if actual == \"D\" and prediction == \"R\":\n",
        "          dem_as_rep += 1\n",
        "        elif actual == \"R\" and prediction == \"D\":\n",
        "          rep_as_dem += 1\n",
        "        else:\n",
        "          other_mis +=1\n",
        "  accuracy = total_correct / total\n",
        "  print(\"Accuracy:\", accuracy)\n",
        "  print(\"Misclassified Dem as Rep:\", dem_as_rep)\n",
        "  print(\"Misclassified Rep as Dem:\", rep_as_dem)\n",
        "  print(\"Misclassified other:\", other_mis) \n",
        "  return accuracy   \n",
        "\n",
        "total_accuracy = 0\n",
        "for index in range(num_folds):\n",
        "  test_handles = folds[index]\n",
        "  dem_dist = freq_dicts[index][0]\n",
        "  rep_dist = freq_dicts[index][1]\n",
        "  print(\"*************************\\nResults for fold\", index)\n",
        "  total_accuracy += evaluate_individual_tweets(dem_dist, rep_dist, test_handles)\n",
        "\n",
        "print(\"*************************\\nAverage Accuracy:\", total_accuracy / num_folds)  "
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*************************\n",
            "Results for fold 0\n",
            "Accuracy: 0.8599527835995279\n",
            "Misclassified Dem as Rep: 6356\n",
            "Misclassified Rep as Dem: 4861\n",
            "Misclassified other: 410\n",
            "*************************\n",
            "Results for fold 1\n",
            "Accuracy: 0.8600009636000097\n",
            "Misclassified Dem as Rep: 6372\n",
            "Misclassified Rep as Dem: 4841\n",
            "Misclassified other: 410\n",
            "*************************\n",
            "Results for fold 2\n",
            "Accuracy: 0.8570860735708608\n",
            "Misclassified Dem as Rep: 6333\n",
            "Misclassified Rep as Dem: 5122\n",
            "Misclassified other: 410\n",
            "*************************\n",
            "Results for fold 3\n",
            "Accuracy: 0.8573269735732697\n",
            "Misclassified Dem as Rep: 6423\n",
            "Misclassified Rep as Dem: 5012\n",
            "Misclassified other: 410\n",
            "*************************\n",
            "Results for fold 4\n",
            "Accuracy: 0.8631085736310857\n",
            "Misclassified Dem as Rep: 6035\n",
            "Misclassified Rep as Dem: 4920\n",
            "Misclassified other: 410\n",
            "*************************\n",
            "Average Accuracy: 0.8594950735949507\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EYwfcF0sudro"
      },
      "source": [
        "Here, we see that the average accuracy is about 85.9%. While this is less than the accuracy for classifying an entire account, this is still impressive accuracy considering how short individual tweets are."
      ]
    }
  ]
}