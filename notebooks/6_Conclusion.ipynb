{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "6 - Conclusion.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_tciInaZ_ugG"
      },
      "source": [
        "In this notebook, I summarize the results, and list some possibilities for further study on this project."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rV8NmFySAjBh"
      },
      "source": [
        "# Summary of Results\n",
        "\n",
        "Here, I summarize and comment on the results of this project.\n",
        "\n",
        "\n",
        "*   In Notebook 1 - Tweet Scraper, I used Tweepy and the Twitter API to collect a dataset of tweets. This data collection was done by running the notebook every day for twelve days.\n",
        "\n",
        "*   In Notebook 2 - Data Preprocessing, I combined the data collection on each day into a dataset of tweets. I then did some preprocessing on the dataset, creating datastructures that were convenient for using the data for analysis in later notebooks. The code from this notebook is repeated in each of the following notebooks, since it prepares the data for analysis.\n",
        "\n",
        "*   In Notebook 3 - Word Frequencies by Party, I build a topic model for each of the parties, computing the frequencies of words in tweets by member of the democratic party and the republican party. From these, I was able to see the most frequent words tweeted by members of each party. Interestingly, the democrats were focused on the infrastructure act, while the republicans were focused on tweeting about President Biden.\n",
        "\n",
        "*   In Notebook 4 - Political Party Classifier, I trained a maximum likelihood classifier to classifier accounts by political party, and later individual tweets by political party. I used cross validation to average the accuracy over multiple training-testing splits. I found that classifying accounts as democrat vs. republican had an average accuracy of about 95.7%. Classifying inidivudal tweets had an average accuracy of about 85.9%. Both of these accuracies are quite good, and significantly better than I expected at the beginning of this project. This maybe partially due to the large number of retweets in the dataset, and investigating this impact is described in the future work section below.\n",
        "\n",
        "\n",
        "*   In Notebook 5 - LDA, I trained a Latent Dirichlet Allocation (LDA) model, to automatically extract topics from the dataset. Comparing the topics generated with the political parties, one of the topics leaned democrat while the other leaned republican, showing that there is a clear difference in what politicians from the two parties tweet about.\n",
        "\n",
        "Overall, I was surprised by how successful this project was at associating political party with tweet text. This may be indicative of the current polarization in United States politics, with clear divisions of democrats and republicans.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1wi-zq5OAmA0"
      },
      "source": [
        "# Further Study\n",
        "\n",
        "Finally, I list some possibilities for further study on this project, which I was not able to complete due to time limitations.\n",
        "\n",
        "*   We've noted that there are many retweets in the dataset, and this is probably part of the reason why the classifiers that we trained were so accurate. It would be interesting to explore the impact of these retweets, by removing retweets from the dataset, and then repeating the investigations from this project.\n",
        "*   It would be interesting to explore how the topic distributions for democrats and republicans change over time. For instance, in this project, we saw that infrastructure was commonly tweeted about by democrats, likely because of the passage of the new Infrastructure act. However, in a month or more, the most frequent word would probably change.\n",
        "*   It would also be worthwhile to explore how the choice of classification model or topic model affects the result. For this project, I only used a maximum likelihood classifier, and LDA. It would be interesting to try different models, such as PLSA, neural networks, or support vector machines. Different options could also be explored for the models, including using a background model.\n",
        "\n"
      ]
    }
  ]
}