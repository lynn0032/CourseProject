{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2 - Data Preprocessing.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cW0Yse4Di0of"
      },
      "source": [
        "In this notebook, we load and preprocess the data in preparation for the analysis in later sections.\n",
        "\n",
        "The tweet data is stored in csv files (as created in the previous notebook, on scraping tweets), with one csv file for each day of data collection. These files are posted in the github repository for this project. The following block of code loads the data from these files, and combines them into a single pandas dataframe.\n",
        "\n",
        "We look at the summary of this data, seeing there are three parties represented in this dataset. These are \"D\" (democrat), \"R\" (republican), and \"I\" (independent). There are 115,982 Tweet texts (though this includes some duplicates, which we will deal with next), with 23,498 unique."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        },
        "id": "_uU5MJ3lfg4C",
        "outputId": "5b297864-d7d6-4a9d-f63f-3b80792e11ea"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# List of dates for which data was gathered. This is used in the file names.\n",
        "dates = [\"11\" + str(day) for day in range(15, 27)]\n",
        "\n",
        "# Location of the csv files containing tweets\n",
        "location = \"https://raw.githubusercontent.com/lynn0032/CourseProject/main/data_files/\"\n",
        "\n",
        "column_names = [\"Index\", \"Twitter Handle\", \"Created At\", \"ID\", \"Tweet Text\", \"State\", \"Branch\", \"Last Name\", \"First Name\"]\n",
        "tweets_df = pd.DataFrame(columns = column_names)\n",
        "\n",
        "# Load tweet data from each day, and combine them in the dataframe tweets_df\n",
        "for d in dates:\n",
        "  file_name = \"all_tweets_\" + d + \".csv\"\n",
        "  day_df = pd.read_csv(location + file_name)\n",
        "  tweets_df = pd.concat([tweets_df, day_df], axis = 0)\n",
        "\n",
        "#Drop the extra Index column\n",
        "tweets_df = tweets_df.drop(columns = [\"Index\"])\n",
        "\n",
        "tweets_df.describe(include = 'all')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Twitter Handle</th>\n",
              "      <th>Created At</th>\n",
              "      <th>ID</th>\n",
              "      <th>Tweet Text</th>\n",
              "      <th>State</th>\n",
              "      <th>Branch</th>\n",
              "      <th>Last Name</th>\n",
              "      <th>First Name</th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Party</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>114069</td>\n",
              "      <td>115982</td>\n",
              "      <td>1.159820e+05</td>\n",
              "      <td>115982</td>\n",
              "      <td>115995</td>\n",
              "      <td>115995</td>\n",
              "      <td>115353</td>\n",
              "      <td>115353</td>\n",
              "      <td>115995.000000</td>\n",
              "      <td>115353</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unique</th>\n",
              "      <td>536</td>\n",
              "      <td>22551</td>\n",
              "      <td>NaN</td>\n",
              "      <td>23498</td>\n",
              "      <td>488</td>\n",
              "      <td>2</td>\n",
              "      <td>491</td>\n",
              "      <td>340</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top</th>\n",
              "      <td>SenBlumenthal</td>\n",
              "      <td>2021-08-01 00:30:42</td>\n",
              "      <td>NaN</td>\n",
              "      <td>RT @POTUS: Join me as I sign the Bipartisan In...</td>\n",
              "      <td>New York 2nd District</td>\n",
              "      <td>U.S. Representative</td>\n",
              "      <td>Johnson</td>\n",
              "      <td>Mike</td>\n",
              "      <td>NaN</td>\n",
              "      <td>D</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>freq</th>\n",
              "      <td>214</td>\n",
              "      <td>36</td>\n",
              "      <td>NaN</td>\n",
              "      <td>82</td>\n",
              "      <td>642</td>\n",
              "      <td>94595</td>\n",
              "      <td>1284</td>\n",
              "      <td>2996</td>\n",
              "      <td>NaN</td>\n",
              "      <td>58203</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.449471e+18</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4837.255925</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5.338167e+16</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2797.926267</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>6.115793e+17</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.458628e+18</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2416.000000</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.460784e+18</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4833.000000</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.461734e+18</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>7249.000000</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.464371e+18</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>9757.000000</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Twitter Handle           Created At  ...     Unnamed: 0   Party\n",
              "count          114069               115982  ...  115995.000000  115353\n",
              "unique            536                22551  ...            NaN       3\n",
              "top     SenBlumenthal  2021-08-01 00:30:42  ...            NaN       D\n",
              "freq              214                   36  ...            NaN   58203\n",
              "mean              NaN                  NaN  ...    4837.255925     NaN\n",
              "std               NaN                  NaN  ...    2797.926267     NaN\n",
              "min               NaN                  NaN  ...       0.000000     NaN\n",
              "25%               NaN                  NaN  ...    2416.000000     NaN\n",
              "50%               NaN                  NaN  ...    4833.000000     NaN\n",
              "75%               NaN                  NaN  ...    7249.000000     NaN\n",
              "max               NaN                  NaN  ...    9757.000000     NaN\n",
              "\n",
              "[11 rows x 10 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fbWRDVXsjvMm"
      },
      "source": [
        "The Twitter API does not allow for restricting tweets collected by dates, so in many cases, retrieved 18 tweets for each day resulted in collecting tweets from the previous day or earlier. This results in duplicate tweets in the dataset. The following block of code eliminates these duplicates, leaving us with 84,948 distinct tweets. Note that the text isn't distinct for all tweets, since politicians will frequently retweet other tweets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        },
        "id": "wfXHyw-SjA4c",
        "outputId": "a8d332ec-6dd9-4246-eb18-efffc6e7552d"
      },
      "source": [
        "#Remove duplicate tweets\n",
        "tweets_df = tweets_df.drop_duplicates()\n",
        "\n",
        "tweets_df.describe(include = 'all')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Twitter Handle</th>\n",
              "      <th>Created At</th>\n",
              "      <th>ID</th>\n",
              "      <th>Tweet Text</th>\n",
              "      <th>State</th>\n",
              "      <th>Branch</th>\n",
              "      <th>Last Name</th>\n",
              "      <th>First Name</th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Party</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>83026</td>\n",
              "      <td>84948</td>\n",
              "      <td>8.494800e+04</td>\n",
              "      <td>84948</td>\n",
              "      <td>84952</td>\n",
              "      <td>84952</td>\n",
              "      <td>84310</td>\n",
              "      <td>84310</td>\n",
              "      <td>84952.000000</td>\n",
              "      <td>84310</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unique</th>\n",
              "      <td>536</td>\n",
              "      <td>22551</td>\n",
              "      <td>NaN</td>\n",
              "      <td>23498</td>\n",
              "      <td>488</td>\n",
              "      <td>2</td>\n",
              "      <td>491</td>\n",
              "      <td>340</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top</th>\n",
              "      <td>SenBlumenthal</td>\n",
              "      <td>2021-11-24 00:07:06</td>\n",
              "      <td>NaN</td>\n",
              "      <td>RT @POTUS: Join me as I sign the Bipartisan In...</td>\n",
              "      <td>Louisiana 5th District</td>\n",
              "      <td>U.S. Representative</td>\n",
              "      <td>Johnson</td>\n",
              "      <td>John</td>\n",
              "      <td>NaN</td>\n",
              "      <td>D</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>freq</th>\n",
              "      <td>214</td>\n",
              "      <td>36</td>\n",
              "      <td>NaN</td>\n",
              "      <td>64</td>\n",
              "      <td>642</td>\n",
              "      <td>68214</td>\n",
              "      <td>870</td>\n",
              "      <td>2062</td>\n",
              "      <td>NaN</td>\n",
              "      <td>45648</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.457561e+18</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4880.892916</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.658129e+16</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2792.262229</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>6.115793e+17</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.459545e+18</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2509.000000</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.461051e+18</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4907.000000</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.461803e+18</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>7286.250000</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.464371e+18</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>9757.000000</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Twitter Handle           Created At  ...    Unnamed: 0  Party\n",
              "count           83026                84948  ...  84952.000000  84310\n",
              "unique            536                22551  ...           NaN      3\n",
              "top     SenBlumenthal  2021-11-24 00:07:06  ...           NaN      D\n",
              "freq              214                   36  ...           NaN  45648\n",
              "mean              NaN                  NaN  ...   4880.892916    NaN\n",
              "std               NaN                  NaN  ...   2792.262229    NaN\n",
              "min               NaN                  NaN  ...      0.000000    NaN\n",
              "25%               NaN                  NaN  ...   2509.000000    NaN\n",
              "50%               NaN                  NaN  ...   4907.000000    NaN\n",
              "75%               NaN                  NaN  ...   7286.250000    NaN\n",
              "max               NaN                  NaN  ...   9757.000000    NaN\n",
              "\n",
              "[11 rows x 10 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PXj1NWBkj9tt"
      },
      "source": [
        "To tokenize words, remove stop words, and stem words, I use nltk."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "okHvRBU2j9Jw",
        "outputId": "fe05b61a-b65b-4850-931e-6a8c16d9cb46"
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o17YsR4ZkDGQ"
      },
      "source": [
        "The work to preprocess words is divided up into functions. \n",
        "\n",
        "The function remove_punctuation takes a word as an argument, and returns the string with all characters removed except for lowercase letters and \"@\" and \"#\" (kept because they indicate tweeting at another count, and hashtag).\n",
        "\n",
        "The function get_words takes a tweet, and splits it into words based on where spaces occur. It uses the function remove_punctuation to remove extra punctuation, then uses the stopwords from nltk to remove stopwords."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vxo5IK6CkBCb"
      },
      "source": [
        "def remove_punctuation(word:str) -> str:\n",
        "  \"\"\"Takes a word, and returns the word with characters \n",
        "  except for lowercase letters and @ and # removed\"\"\"\n",
        "  new_word = \"\"\n",
        "  allowed = \"abcdefghijklmnopqrstuvwxyz@#\"\n",
        "  for char in word:\n",
        "    if char in allowed:\n",
        "      new_word += char\n",
        "  return new_word\n",
        "\n",
        "stop_words = stopwords.words('english')     #stop words from nltk\n",
        "\n",
        "def get_words(text_str) -> list:\n",
        "  \"\"\"Takes a tweet, splits it into words based on spaces,\n",
        "  removes extra punctuation from the words, and then\n",
        "  removes stop words\"\"\"\n",
        "  words = [remove_punctuation(w.lower()) for w in text_str.split(\" \")]\n",
        "  filtered_words = [w for w in words if w not in stop_words]\n",
        "  return [word for word in filtered_words if word != \"\"]"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QjcSpP8lkKHb"
      },
      "source": [
        "The following functions are used to determine some common aspects of tweets: whether it was a retweet, who was tweeted at (with @handle), and any hashtags (#hashtag) included in the tweet.\n",
        "\n",
        "The function retweet takes a list of words from a tweet, as returned by the function get_words defined above, and returns True if the tweet is a retweet. It returns False otherwise. This is identified by looking for 'rt' in the list of words from the tweet.\n",
        "\n",
        "The function tweet_at takes a list of words from a tweet, as returned by the function get_words, and returns a list of handles tweeted at in the tweet. These are identified by looking for '@' at the beginning of words in the tweet.\n",
        "\n",
        "The function hash_tags takes a list of words from a tweet, as returned by the function get_words, and returns a list of hashtags referenced in the tweet. These are identified by looking for '#' at the beginning of words in the tweet."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tu3ICkZJkGEN"
      },
      "source": [
        "def retweet(words:list) -> bool:\n",
        "  \"\"\"Takes a list of words from a tweet (as returned by get_words), \n",
        "  and returns True if 'rt' is one of the words (which means that \n",
        "  the tweet is a retweet)\"\"\"\n",
        "  return ('rt' in words)\n",
        "\n",
        "def tweet_at(words:list) -> list:\n",
        "  \"\"\"Takes a list of words from a tweet (as returned by get_words),\n",
        "  and returns a list of handles that are tweeted at in the tweet\"\"\"\n",
        "  at = []\n",
        "  for word in words:\n",
        "    if word[0] == '@':\n",
        "      at.append(word[1:])\n",
        "  return at\n",
        "\n",
        "def hash_tags(words:list) -> list:\n",
        "  \"\"\"Takes a list of words from a tweet (as returned by get_words),\n",
        "  and returns a list of all hashtags included in the tweet\"\"\"\n",
        "  tags = []\n",
        "  for word in words:\n",
        "    if word[0] == '#':\n",
        "      tags.append(word[1:])\n",
        "  return tags"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0-hG6dd0kNsS"
      },
      "source": [
        "The function word_counts takes a list of words from a tweet, as returned by the function get_words, and returns a dictionary of word counts for words in the tweet: {word:count}. Words beginning with '@' or '#' are omitted, since these are tweeted at someone and hashtags, and they will be stored separately. The word 'rt' is also ommitted, since it indicates a retweet. Links are also excluded, determined by containing 'http'."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YZp8sZHDkM6_"
      },
      "source": [
        "ps = PorterStemmer()    # Word stemmer from nltk\n",
        "\n",
        "def word_counts(words:list) -> dict:\n",
        "  \"\"\"Takes a list of words from a tweet (as returned by get_words),\n",
        "  and returns a dictionary of the counts of words from the tweet\"\"\"\n",
        "  counts_dict = {}\n",
        "  for word in words:\n",
        "    if word[0] != '@' and word[0] != '#' and word != 'rt' and 'http' not in word:\n",
        "      word = ps.stem(word)\n",
        "      if word in counts_dict:\n",
        "        counts_dict[word] += 1\n",
        "      else:\n",
        "        counts_dict[word] = 1\n",
        "  return counts_dict"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "11MaTTGHkS5K"
      },
      "source": [
        "The function parse_tweet uses the functions defined above to create a dictionary with information on a tweet. It takes the original text of the tweet, and uses the function get_words to separate the text into individual words. The dictionary for the tweet stores the following information:\n",
        "\n",
        "\n",
        "*   Under the key \"counts\", a dictionary with the word counts from the tweet, which is returned by calling the function word_counts on the words from the tweet.\n",
        "*   Under the key \"retweets\", a boolean indicating whether or not the tweet is a retweet. This is done using the function retweet defined above.\n",
        "*   Under the key \"at\", a list of handles tweeted at in this tweet, as constructed by the function tweet_at defined above.\n",
        "*   Under the key \"tags\", a list of hashtags included in this tweet, as constructed by the function hash_tags defined above.\n",
        "\n",
        "Finally, we call the function parse_tweet on every tweet in the dataset tweets_df, constructing a dictionary tweet_dict where the keys are the text of a tweet, and the corresponding value is the dictionary created by parse_tweet.\n",
        "\n",
        "For example, if example_tweet is the text of a tweet, we could get the word counts dictionary for the tweet with: tweet_dict[example_tweet][\"counts\"].\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v9uRkdWEkSRv"
      },
      "source": [
        "def parse_tweet(text:str) -> dict:\n",
        "  words = get_words(text)\n",
        "  return {\"counts\": word_counts(words), \"retweet\": retweet(words), \"at\": tweet_at(words), \"tags\": hash_tags(words)}\n",
        "  \n",
        "tweet_dict = {}\n",
        "for tweet in tweets_df['Tweet Text']:\n",
        "  tweet = str(tweet)\n",
        "  tweet_dict[tweet] = parse_tweet(tweet)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S21LAulQkYvK"
      },
      "source": [
        "Next, we construct a dictionary storing the political party associated with each Twitter handle, so that we can easily look up these parties.\n",
        "\n",
        "This is done by taking the Twitter handle and party from each record in the dataframe tweets_df, iterating through these and adding them to the dictionary parties."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "23DYXzL9kbPm"
      },
      "source": [
        "handle_parties_df = tweets_df[['Twitter Handle', 'Party']]\n",
        "handle_parties_df.drop_duplicates()\n",
        "parties = {}\n",
        "for index, row in handle_parties_df.iterrows():\n",
        "  handle = row['Twitter Handle']\n",
        "  parties[handle] = row['Party']"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BPY4KNAT6Rjc"
      },
      "source": [
        "Next, we build a word count dictionary for each handle. This will be hepful for classifying accounts as democrat or republican.\n",
        "\n",
        "To do this, we define a function that takes a twitter handle, and returns a dictionary of word counts from all tweets from that handle."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G9iV0QsK6SFg"
      },
      "source": [
        "def handle_word_counts(handle):\n",
        "  handle_df = tweets_df[tweets_df['Twitter Handle'] == handle]\n",
        "  all_counts = {}\n",
        "  for tweet in handle_df['Tweet Text']:\n",
        "    tweet = str(tweet)\n",
        "    for word in tweet_dict[tweet]['counts']:\n",
        "      if word in all_counts:\n",
        "        all_counts[word] += tweet_dict[tweet]['counts'][word]\n",
        "      else:\n",
        "        all_counts[word] = tweet_dict[tweet]['counts'][word]\n",
        "  return all_counts"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9bcAVUKc6TJs"
      },
      "source": [
        "Now, we use this function to compute word counts for each handle. These are stored in a dictionary, with the handle as the key and the dictionary of word counts as the corresponding value."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6FBj9L3D6Tx3"
      },
      "source": [
        "handles = list(set(tweets_df['Twitter Handle'].unique()))\n",
        "\n",
        "handle_counts_dict = {}\n",
        "for handle in handles:\n",
        "  handle_counts_dict[handle] = handle_word_counts(handle)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GyR_rPqpkhCv"
      },
      "source": [
        "The code in this notebook set up the datastructures needed for our data analysis, and these datastructures will be used in subsequent notebooks for analysis."
      ]
    }
  ]
}